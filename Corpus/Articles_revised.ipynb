{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPO7HUQxDNcIl2PJdg2io0Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Spring2024/blob/main/Corpus/Articles_revised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding articles in a text"
      ],
      "metadata": {
        "id": "v-MKVHMBRu1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnSTfHvxRuDZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def count_articles(text):\n",
        "    # Regex pattern to match 'a', 'an', 'the'\n",
        "    # Using word boundaries (\\b) to ensure we're not matching substrings within larger words\n",
        "    pattern = r'\\b(a|an|the)\\b'\n",
        "\n",
        "    # Using case-insensitive matching to catch 'A', 'An', 'The', etc.\n",
        "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "\n",
        "    # Count the frequency of each article\n",
        "    article_counts = {'a': 0, 'an': 0, 'the': 0}\n",
        "    for match in matches:\n",
        "        article_counts[match.lower()] += 1\n",
        "\n",
        "    return article_counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "text = \"A cat and an apple were on the table. The cat jumped over a dog.\"\n",
        "article_counts = count_articles(text)\n",
        "print(article_counts)\n"
      ],
      "metadata": {
        "id": "SX6O12DkR6tD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ [text1: living light](https://raw.githubusercontent.com/MK316/Class_Spring2022/main/Ch02_Living_light.txt)\n",
        "+ [text2: Visual village](https://raw.githubusercontent.com/MK316/Class_Spring2022/main/Ch01.Visual.Village.txt)\n",
        "+[text3:TED-photo](https://raw.githubusercontent.com/MK316/Spring2024/main/Corpus/tedphoto.txt)"
      ],
      "metadata": {
        "id": "oaB22hYhTBlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input()\n",
        "article_counts = count_articles(text)\n",
        "print(f\"Use of articles: {article_counts}\")"
      ],
      "metadata": {
        "id": "ag77rBjcR7VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two texts to compare"
      ],
      "metadata": {
        "id": "X-jhH1NAT8Kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assing texts A and B"
      ],
      "metadata": {
        "id": "Urs0R4FiURqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "textA=input(\"TextA: \")\n",
        "textB=input(\"TextB:\" )"
      ],
      "metadata": {
        "id": "oRrUYBFkUUrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example texts\n",
        "text1 = \"A cat and an apple were on the table. The cat jumped over a dog.\"\n",
        "text2 = \"It was a bright cold day in April, and the clocks were striking thirteen. Winston Smith, his chin nuzzled into his breast in an effort to escape the vile wind, slipped quickly through the glass doors of Victory Mansions, though not quickly enough to prevent a swirl of gritty dust from entering along with him.\"\n"
      ],
      "metadata": {
        "id": "Omg7tDLJUe8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the maximum length\n",
        "max_length = 4746\n",
        "\n",
        "# Trim the string to the maximum length\n",
        "trimmed = textA[:max_length]\n",
        "\n",
        "len(trimmed)"
      ],
      "metadata": {
        "id": "AybKLCWeR6sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textA = trimmed"
      ],
      "metadata": {
        "id": "7bbtH-VdSN5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Text comparison in terms of average sentence length and article use\n",
        "import re\n",
        "import pandas as pd\n",
        "from statistics import mean\n",
        "\n",
        "def analyze_text(text):\n",
        "    words = re.findall(r'\\b\\w+\\b', text)\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', text)\n",
        "    sentence_lengths = [len(re.findall(r'\\b\\w+\\b', sentence)) for sentence in sentences]\n",
        "\n",
        "    article_counts = re.findall(r'\\b(a|an|the)\\b', text, re.IGNORECASE)\n",
        "    indefinite_count = sum(1 for word in article_counts if word.lower() in ['a', 'an'])\n",
        "    definite_count = sum(1 for word in article_counts if word.lower() == 'the')\n",
        "\n",
        "    return {\n",
        "        'Length': len(text),\n",
        "        'N_Word': len(words),\n",
        "        'N_Sent': len(sentences),\n",
        "        'Avg_SentLen_inwords': mean(sentence_lengths) if sentence_lengths else 0,\n",
        "        'Indef_Articles': indefinite_count,\n",
        "        'Def_Articles': definite_count\n",
        "    }\n",
        "\n",
        "\n",
        "# Analyze texts\n",
        "results_text1 = analyze_text(textA)\n",
        "results_text2 = analyze_text(textB)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame([results_text1, results_text2],\n",
        "                  index=['Text A', 'Text B'])\n",
        "\n",
        "# Display the DataFrame\n",
        "df\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PxZpTi4-T98p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TED script preprocessing using Regular Expression"
      ],
      "metadata": {
        "id": "tLhY4RyUJ4Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "TGXRLlV7KVIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ted = input()"
      ],
      "metadata": {
        "id": "FPb1XHs3KcYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "00:46\n",
        "My process begins by photographing iconic locations, places that are part of what I call our collective memory. I photograph from a fixed vantage point, and I never move. I capture the fleeting moments of humanity and light as time passes. Photographing for anywhere from 15 to 30 hours and shooting over 1,500 images\n",
        "\n",
        "\\\\"
      ],
      "metadata": {
        "id": "3EP9qEJTOb-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # cleaned = re.sub(r\"\\d\\d:\\d\\d\", \"\", ted)\n",
        "cleaned = re.sub(r'\\b\\d+:\\d+\\b', '', ted)\n",
        "cleaned"
      ],
      "metadata": {
        "id": "HrQFDXVpKxhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3iEDtWmdRHM7"
      }
    }
  ]
}