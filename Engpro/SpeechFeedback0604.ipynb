{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM1Z4Em0UTC72Gg1shHeiBL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Spring2024/blob/main/Engpro/SpeechFeedback0604.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio>=2.9.4\n",
        "!pip install SpeechRecognition>=3.8.1\n",
        "!pip install python-Levenshtein>=0.12.2\n",
        "!pip install SoundFile>=0.10.3.post1\n",
        "# pandas>=1.3.5\n",
        "# numpy>=1.21.6"
      ],
      "metadata": {
        "id": "yXRxJvPysAjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6L9KlKFr8Dw"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from Levenshtein import ratio\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataframe with sentences ordered from easy to hard\n",
        "data = {\n",
        "    \"Sentences\": [\n",
        "        \"A stitch in time saves nine.\",\n",
        "        \"To be or not to be, that is the question.\",\n",
        "        \"Five cats were living in safe caves.\",\n",
        "        \"Hives give shelter to bees in large caves.\",\n",
        "        \"His decision to plant a rose was amazing.\",\n",
        "        \"She sells sea shells by the sea shore.\",\n",
        "        \"The colorful parrot likes rolling berries.\",\n",
        "        \"Time flies like an arrow; fruit flies like a banana.\",\n",
        "        \"Good things come to those who wait.\",\n",
        "        \"All human beings are born free and equal in dignity and rights.\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def transcribe_audio(file_info):\n",
        "    r = sr.Recognizer()\n",
        "    with tempfile.NamedTemporaryFile(delete=True, suffix=\".wav\") as tmpfile:\n",
        "        sf.write(tmpfile.name, data=file_info[1], samplerate=44100, format='WAV')\n",
        "        tmpfile.seek(0)\n",
        "        with sr.AudioFile(tmpfile.name) as source:\n",
        "            audio_data = r.record(source)\n",
        "    try:\n",
        "        text = r.recognize_google(audio_data)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Could not understand audio\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Could not request results; {e}\"\n",
        "\n",
        "def pronunciation_correction(expected_text, file_info):\n",
        "    user_spoken_text = transcribe_audio(file_info)\n",
        "    similarity = ratio(expected_text.lower(), user_spoken_text.lower())\n",
        "    description = f\"{similarity:.2f}\"\n",
        "\n",
        "    if similarity >= 0.9:\n",
        "        feedback = \"Excellent pronunciation!\"\n",
        "    elif similarity >= 0.7:\n",
        "        feedback = \"Good pronunciation!\"\n",
        "    elif similarity >= 0.5:\n",
        "        feedback = \"Needs improvement.\"\n",
        "    else:\n",
        "        feedback = \"Poor pronunciation, try to focus more on clarity.\"\n",
        "\n",
        "    return feedback, description\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    with gr.Row():\n",
        "        sentence_dropdown = gr.Dropdown(choices=df['Sentences'].tolist(), label=\"Select a Sentence\")\n",
        "        selected_sentence_output = gr.Textbox(label=\"Selected Text\", interactive=False)\n",
        "    audio_input = gr.Audio(label=\"Upload Audio File\", type=\"numpy\")\n",
        "    check_pronunciation_button = gr.Button(\"Check Pronunciation\")\n",
        "    pronunciation_feedback = gr.Textbox(label=\"Pronunciation Feedback\")\n",
        "    pronunciation_score = gr.Number(label=\"Pronunciation Accuracy Score: 0 (No Match) ~ 1 (Perfect)\")\n",
        "\n",
        "    sentence_dropdown.change(lambda x: x, inputs=sentence_dropdown, outputs=selected_sentence_output)\n",
        "    check_pronunciation_button.click(\n",
        "        pronunciation_correction,\n",
        "        inputs=[sentence_dropdown, audio_input],\n",
        "        outputs=[pronunciation_feedback, pronunciation_score]\n",
        "    )\n",
        "\n",
        "app.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from Levenshtein import ratio\n",
        "import tempfile\n",
        "import soundfile as sf\n",
        "\n",
        "def transcribe_audio(file_info):\n",
        "    r = sr.Recognizer()\n",
        "    with tempfile.NamedTemporaryFile(delete=True, suffix=\".wav\") as tmpfile:\n",
        "        # Write the sound file to the temporary file\n",
        "        sf.write(tmpfile.name, data=file_info[1], samplerate=44100, format='WAV')\n",
        "        tmpfile.seek(0)\n",
        "        with sr.AudioFile(tmpfile.name) as source:\n",
        "            audio_data = r.record(source)  # Read the entire audio file\n",
        "    try:\n",
        "        text = r.recognize_google(audio_data)  # Using Google Web Speech API to transcribe the audio\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Could not understand audio\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Could not request results; {e}\"\n",
        "\n",
        "def pronunciation_correction(expected_text, file_info):\n",
        "    user_spoken_text = transcribe_audio(file_info)\n",
        "    similarity = ratio(expected_text.lower(), user_spoken_text.lower())  # Calculate the Levenshtein ratio\n",
        "    description = f\"{similarity:.2f}\"  # Format similarity score to 2 decimal places\n",
        "\n",
        "    if similarity >= 0.9:\n",
        "        feedback = \"Excellent pronunciation!\"\n",
        "    elif similarity >= 0.7:\n",
        "        feedback = \"Good pronunciation!\"\n",
        "    elif similarity >= 0.5:\n",
        "        feedback = \"Needs improvement.\"\n",
        "    else:\n",
        "        feedback = \"Poor pronunciation, try to focus more on clarity.\"\n",
        "\n",
        "    return feedback, description\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    with gr.Row():\n",
        "        text_input = gr.Textbox(label=\"Enter or paste your text here\")\n",
        "    audio_input = gr.Audio(label=\"Upload Audio File\", type=\"numpy\")\n",
        "    check_pronunciation_button = gr.Button(\"Check Pronunciation\")\n",
        "    pronunciation_feedback = gr.Textbox(label=\"Pronunciation Feedback\")\n",
        "    pronunciation_score = gr.Number(label=\"Pronunciation Accuracy Score: 0 (No Match) ~ 1 (Perfect)\")\n",
        "\n",
        "    check_pronunciation_button.click(\n",
        "        pronunciation_correction,\n",
        "        inputs=[text_input, audio_input],\n",
        "        outputs=[pronunciation_feedback, pronunciation_score]\n",
        "    )\n",
        "\n",
        "app.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "c0O-U4wfr9Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pronunciation Feedback: WER, Fluency, WPM\n",
        "\n",
        "Fluency checking"
      ],
      "metadata": {
        "id": "EaDnYQI0vGdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "metadata": {
        "id": "Pu1iXDS7vJ2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ Sample text: the rainbow passage\n",
        "+ Native samples:\n",
        "\n",
        "|Speaker|WER|Fluency|WPM|\n",
        "|--|--|--|--|\n",
        "|Female| WER: 0.11| Fluency: 70 pauses| 174 WPM|\n",
        "|Male | WER: 0.12| Fluency: 73 pauses| 168 WPM|"
      ],
      "metadata": {
        "id": "wH5x1yXO0iKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Language Application: WER, Fluency (in N of pauses), WPM (Words per minute)\n",
        "import gradio as gr\n",
        "import speech_recognition as sr\n",
        "from Levenshtein import distance as lev_distance, ratio\n",
        "import tempfile\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "def analyze_speech(file_info):\n",
        "    r = sr.Recognizer()\n",
        "    with tempfile.NamedTemporaryFile(delete=True, suffix=\".wav\") as tmpfile:\n",
        "        # Write the sound file to the temporary file\n",
        "        sf.write(tmpfile.name, data=file_info[1], samplerate=44100, format='WAV')\n",
        "        tmpfile.seek(0)\n",
        "\n",
        "        # Load audio for pause analysis and speech rate\n",
        "        y, sr_lib = librosa.load(tmpfile.name, sr=None)  # Load the file with the original sampling rate\n",
        "        duration = librosa.get_duration(y=y, sr=sr_lib)\n",
        "\n",
        "        # Detect pauses\n",
        "        pause_frames = librosa.effects.split(y, top_db=32)\n",
        "        pauses = [(start, end) for start, end in pause_frames if (end - start) / sr_lib > 0.5]\n",
        "        num_pauses = len(pauses)\n",
        "\n",
        "        with sr.AudioFile(tmpfile.name) as source:\n",
        "            audio_data = r.record(source)\n",
        "        text = r.recognize_google(audio_data)\n",
        "\n",
        "        return text, num_pauses, duration, len(text.split())\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    ref_words = reference.split()\n",
        "    hyp_words = hypothesis.split()\n",
        "    edit_distance = lev_distance(ref_words, hyp_words)\n",
        "    wer = edit_distance / len(ref_words) if ref_words else float('inf')  # Avoid division by zero\n",
        "    return wer\n",
        "\n",
        "def pronunciation_correction(expected_text, file_info):\n",
        "    user_spoken_text, num_pauses, duration, total_words = analyze_speech(file_info)\n",
        "    wer = calculate_wer(expected_text.lower(), user_spoken_text.lower())\n",
        "    wpm = total_words / (duration / 60) if duration > 0 else 0\n",
        "    similarity = ratio(expected_text.lower(), user_spoken_text.lower())\n",
        "\n",
        "    feedback = \"Excellent pronunciation!\" if similarity >= 0.9 else \\\n",
        "               \"Good pronunciation!\" if similarity >= 0.7 else \\\n",
        "               \"Needs improvement.\" if similarity >= 0.5 else \\\n",
        "               \"Poor pronunciation, try to focus more on clarity.\"\n",
        "\n",
        "    description = f\"WER: {wer:.2f}, Fluency: {num_pauses} pauses, {wpm:.0f} WPM\"\n",
        "\n",
        "    return feedback, description\n",
        "\n",
        "with gr.Blocks() as app:\n",
        "    with gr.Row():\n",
        "        text_input = gr.Textbox(label=\"Enter or paste your text here\")\n",
        "    audio_input = gr.Audio(label=\"Upload Audio File\", type=\"numpy\")\n",
        "    check_pronunciation_button = gr.Button(\"Check Pronunciation\")\n",
        "    pronunciation_feedback = gr.Textbox(label=\"Pronunciation Feedback\")\n",
        "    pronunciation_details = gr.Textbox(label=\"Detailed Metrics\")\n",
        "\n",
        "    check_pronunciation_button.click(\n",
        "        pronunciation_correction,\n",
        "        inputs=[text_input, audio_input],\n",
        "        outputs=[pronunciation_feedback, pronunciation_details]\n",
        "    )\n",
        "\n",
        "app.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "yMX7Mzhfv23q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}